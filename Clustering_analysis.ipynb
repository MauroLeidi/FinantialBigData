{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import networkx as nx\n",
    "import community\n",
    "import community.community_louvain as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "from pypfopt import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "import rpy2.robjects.numpy2ri\n",
    "\n",
    "r = robjects.r\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "\n",
    "#importr(\"data.table\")\n",
    "\n",
    "newfunc = r.source(\"libClusteringGiadaMarsiliFast.R\")\n",
    "aggregateClusters=robjects.globalenv[\"aggregateClusters\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Louvain clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_C_minus_C0(lambdas,v,lambda_plus):\n",
    "    N=len(lambdas)\n",
    "    C_clean=np.zeros((N, N))\n",
    "    \n",
    "    v_m=np.matrix(v)\n",
    "    \n",
    "    # TO CHECK: WHY N-1?!?!? isn't range enough to stop at N-1?!\n",
    "    # _s stands for _structure below: \n",
    "    for i in range(N-1):\n",
    "        if lambdas[i]>lambda_plus:\n",
    "            C_clean=C_clean+lambdas[i] * np.dot(v_m[:,i],v_m[:,i].T)  \n",
    "    return C_clean    \n",
    "    \n",
    "def LouvainCorrelationClustering(R):   # R is a matrix of return\n",
    "    \n",
    "    N=R.shape[1]\n",
    "    T=R.shape[0]\n",
    "\n",
    "    q=N*1./T\n",
    "    lambda_plus=(1.+np.sqrt(q))**2\n",
    "\n",
    "    C=R.corr()\n",
    "    lambdas, v = LA.eigh(C)\n",
    "\n",
    "    order = np.argsort(lambdas)\n",
    "    lambdas,v = lambdas[order],v[:,order]\n",
    "      \n",
    "    C_s=compute_C_minus_C0(lambdas,v,lambda_plus)\n",
    "    mygraph= nx.from_numpy_matrix(np.abs(C_s))\n",
    "    partition = community.community_louvain.best_partition(mygraph)\n",
    "    DF=pd.DataFrame.from_dict(partition,orient=\"index\")\n",
    "    DF['StockName'] = R.columns\n",
    "    DF = DF.reset_index()\n",
    "    DF = DF.drop(columns = 'index')\n",
    "    DF = DF.rename({0: 'Cluster'},axis = 'columns')\n",
    "    DF = DF.set_index('StockName')\n",
    "    \n",
    "    return(DF)\n",
    "\n",
    "def drop_nans(df,limit = 0.5):\n",
    "    \"\"\"given a dataframe and a limit value, first drops all the columns that have\n",
    "    more than limit % nans than drops all raws containing at least one nan value\"\"\"\n",
    "    row_num = df.shape[0]\n",
    "    nan_col = df.isnull().sum(axis=0)>(row_num*limit)\n",
    "    df=df.drop(columns=df.columns[nan_col])\n",
    "    return df.dropna()\n",
    "\n",
    "def pick_n_from_k(df,n,seed = 0,onlynames = False):\n",
    "    \"\"\"given a dataframe and a number N, returns a dataframe that \n",
    "    contains n randomly selected columns of the input dataframe\"\"\"\n",
    "    \n",
    "    k = df.shape[0]\n",
    "    \n",
    "    #safety check\n",
    "    assert k >= n, 'K should be >= N'\n",
    "    \n",
    "    #if onlynames is active return only the name of the columns\n",
    "    if onlynames:\n",
    "        random.seed(seed)\n",
    "        return random.sample(list(df.columns), n)\n",
    "    return df.sample(n=n, random_state=seed, axis='columns')\n",
    "\n",
    "def bootstrap_CI(data, nbr_draws):\n",
    "    \"\"\"Given an array and a number of random samples performs bootstrapping to\n",
    "    find the confidence intervals of the mean\"\"\"\n",
    "    # Input: your array and the number of random samples (e.g., 1000 is a good number)\n",
    "    # Output: [lower error, upper error]\n",
    "\n",
    "    means = np.zeros(nbr_draws)\n",
    "    data = np.array(data)\n",
    "\n",
    "    for n in range(nbr_draws):\n",
    "        indices = np.random.randint(0, len(data), len(data))\n",
    "        data_tmp = data[indices] \n",
    "        means[n] = np.nanmean(data_tmp)\n",
    "\n",
    "    return [np.nanpercentile(means, 0.5),np.nanpercentile(means, 99.5)]\n",
    "\n",
    "def optimalWeights(df,verbose = False,shortBan = True):\n",
    "    \"\"\"use pypfopt to compute the optimal weights of the portfolio following markovitz strategy\"\"\"\n",
    "    mu = expected_returns.mean_historical_return(df,returns_data=True,log_returns =True)\n",
    "    S = risk_models.sample_cov(df,returns_data=True,log_returns =True)\n",
    "    if shortBan:\n",
    "        #By default the ef is long only \n",
    "        ef = EfficientFrontier(mu, S)\n",
    "    else:\n",
    "        #Allow negative weights => No shortBan\n",
    "        ef = EfficientFrontier(mu, S, weight_bounds=(-1, 1))\n",
    "    #We could limit the maxweight just by changing the bounds ex: max 10% with shortban weight_bounds=(0, 0.1)\n",
    "    raw_weights = ef.max_sharpe()\n",
    "    cleaned_weights = ef.clean_weights()\n",
    "    if verbose:\n",
    "        return ef.portfolio_performance(verbose=False)\n",
    "    return cleaned_weights\n",
    "\n",
    "def weight_inverse_std(df):\n",
    "    \"\"\"Helper function for the inner-cluster aggregation using inverse std technique.\n",
    "    Given a df containing all data of a cluster rescale the value of returns of each stock\n",
    "    taking as weight the sum(std)/std then aggregate all the returns toghether. \n",
    "    The following methods will use this portfolio of clustered stocks as a single \n",
    "    stock and compose a portfolio\"\"\"\n",
    "    sum_stds = 0\n",
    "    cluster = df['Cluster'].iloc[0]\n",
    "    df = df.drop(columns = ['Cluster']).transpose()\n",
    "    for col in df.columns:\n",
    "        if col != 'Cluster':\n",
    "            sum_stds += 1/df[col].std()\n",
    "    for col in df.columns:\n",
    "        if col != 'Cluster':\n",
    "            df[col] = df[col]*sum_stds/df[col].std()\n",
    "    df = df.sum(axis = 1)\n",
    "    df = df.transpose()\n",
    "    df['Cluster'] = cluster\n",
    "    #df = df.transpose()\n",
    "    return df\n",
    "\n",
    "def compute_clusters_returns(df,clusters,intra_cluster_strategy = 'equal weight'):\n",
    "    \"\"\"given a dataframe and his clusters compute the clusters means\"\"\"\n",
    "    \n",
    "    if intra_cluster_strategy == 'equal weight':\n",
    "        means = df.transpose()\n",
    "        means = pd.merge(means, clusters,left_index = True, right_on='StockName')\n",
    "        means = means.groupby('Cluster').mean().transpose()\n",
    "    elif intra_cluster_strategy == 'inverse std':\n",
    "        #TO DO: test this method\n",
    "        dftr = df.transpose()\n",
    "        dftr = pd.merge(dftr, clusters,left_index = True, right_on='StockName')\n",
    "        means = dftr.groupby('Cluster').apply(lambda x: weight_inverse_std(x))\n",
    "        means = means.drop(columns = ['Cluster']).transpose()\n",
    "    return means\n",
    "\n",
    "def compute_portfolio_return(df,clustering = 'louvian',inter_cluster_strategy ='equal weight',intra_cluster_strategy = 'equal weight'):\n",
    "    \"\"\"given a dataframe, a clustering method and a portfolio weighting strategy\n",
    "    compute the return of the portfolio composed by appling clustering than combining\n",
    "    the clusters using the strategy\"\"\"\n",
    "    if inter_cluster_strategy == 'equal weight':\n",
    "        \n",
    "        if clustering == 'louvian':\n",
    "            clusters = LouvainCorrelationClustering(df)\n",
    "            \n",
    "        elif clustering == 'GiadaMarsili':\n",
    "            clusters = aggregateClusters_(df)\n",
    "            \n",
    "        cluster_means = compute_clusters_returns(df,clusters,intra_cluster_strategy)\n",
    "        portfolio_mean = cluster_means.mean().mean()\n",
    "        portfolio_std = cluster_means.mean(axis = 1).std()\n",
    "        portfolio_std = np.exp((portfolio_std)*252)-1\n",
    "        portfolio_mean = np.exp((portfolio_mean)*252)-1\n",
    "        SharpR = portfolio_mean/portfolio_std\n",
    "        #weight = np.ones(shape = [np.shape(df)[1],1])*1/np.shape(df)[1]\n",
    "        return portfolio_mean,portfolio_std,SharpR#,weight\n",
    "        \n",
    "    elif inter_cluster_strategy == 'inverse std':\n",
    "        \n",
    "        if clustering == 'louvian':\n",
    "            clusters = LouvainCorrelationClustering(df)\n",
    "            \n",
    "        elif clustering == 'GiadaMarsili':\n",
    "            clusters = aggregateClusters_(df)\n",
    "               \n",
    "        cluster_means = compute_clusters_returns(df,clusters,intra_cluster_strategy)\n",
    "        cluster_std = cluster_means.std()\n",
    "        weights = np.array([ i/sum(list(cluster_std)) for i in list(cluster_std)]).T\n",
    "        # I dont know if I can do the mean before or not maybe it changes if variables are dependent\n",
    "        portfolio_mean = (np.array(cluster_means)@weights).mean()\n",
    "        portfolio_std = (np.array(cluster_means)@weights).std()\n",
    "        portfolio_std = np.exp((portfolio_std)*252)-1\n",
    "        portfolio_mean = np.exp((portfolio_mean)*252)-1\n",
    "        SharpR = portfolio_mean/portfolio_std\n",
    "        return portfolio_mean, portfolio_std, SharpR\n",
    "        \n",
    "    elif inter_cluster_strategy == 'markovitz':\n",
    "        if clustering == 'NO clustering':\n",
    "            #no clustering only markovitz portfolio\n",
    "            portfolio_mean, portfolio_std, SharpR = optimalWeights(df,verbose = True)\n",
    "            return portfolio_mean,portfolio_std,SharpR\n",
    "        \n",
    "        elif clustering == 'louvian':\n",
    "            clusters = LouvainCorrelationClustering(df)\n",
    "            \n",
    "        elif clustering == 'GiadaMarsili':\n",
    "            clusters = aggregateClusters_(df)\n",
    "    \n",
    "        cluster_means = compute_clusters_returns(df,clusters,intra_cluster_strategy)\n",
    "        portfolio_mean, portfolio_std, SharpR = optimalWeights(df,verbose = True)\n",
    "        return portfolio_mean,portfolio_std,SharpR\n",
    "             \n",
    "def compute_stategy_avg_return(df,n,n_picks,clustering = 'louvian',inter_cluster_strategy ='equal weight',intra_cluster_strategy = 'equal weight'):\n",
    "    \"\"\"given a dataframe, a number of picks, a size n, a clustering method and a portfolio weighting strategy\n",
    "    compute the average return of n_picks portfolios composed picking at random n stocks from the df,\n",
    "    applying clustering and combining with the weight strategy\"\"\"\n",
    "    portfolio_returns = []\n",
    "    portfolio_risks = []\n",
    "    portfolio_sharpRs = []\n",
    "    for i in range(n_picks):\n",
    "        sub_df = pick_n_from_k(df,n,seed = (i+1))\n",
    "        portfolio_return,portfolio_risk,SharpR = compute_portfolio_return(sub_df,clustering = clustering,inter_cluster_strategy =inter_cluster_strategy,intra_cluster_strategy = intra_cluster_strategy)\n",
    "        print('portfolio nb: ',i, 'return: ',portfolio_return)\n",
    "        portfolio_returns.append(portfolio_return)\n",
    "        portfolio_risks.append(portfolio_risk)\n",
    "        portfolio_sharpRs.append(SharpR*100)\n",
    "    portfolio_returns_mean = sum(portfolio_returns)/len(portfolio_returns)\n",
    "    CI = bootstrap_CI(portfolio_returns,int(n_picks/1.5))\n",
    "    yerr = [-(CI[0]-portfolio_returns_mean),CI[1]-portfolio_returns_mean]\n",
    "    plt.errorbar(1,portfolio_returns_mean,yerr = np.array(yerr).reshape(2,1), fmt='.', ecolor = 'red')\n",
    "    plt.ylabel(\"Mean return of clustering method :\" + clustering +' intra ' + intra_cluster_strategy +' inter ' + inter_cluster_strategy)\n",
    "    plt.title(\"Mean return of clustering method with confidence intervals\")\n",
    "    return portfolio_returns,portfolio_risks,portfolio_sharpRs\n",
    "\n",
    "\n",
    "\n",
    "def aggregateClusters_(R,aggregateClusters=aggregateClusters):\n",
    "    \"\"\"Slight modification to the original function taken from \"libClusteringGiadaMarsiliFast.R\" package.\n",
    "    The modification is made in order to simplify the use and to produce the output with the same format as\n",
    "    the previous clustering method\"\"\"\n",
    "    C = R.corr()\n",
    "    intermediate_result = aggregateClusters(C.values)\n",
    "    nb_clusters = len(intermediate_result[3])\n",
    "    ls_dfs = []\n",
    "    for i in range(nb_clusters):\n",
    "        df = pd.DataFrame(np.array(intermediate_result[3][i]),columns = ['Stock Name'])\n",
    "        df['Cluster'] = i\n",
    "        ls_dfs.append(df)\n",
    "    df = pd.concat(ls_dfs)\n",
    "    df['StockName'] = R.columns\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns = 'index')\n",
    "    df = df.drop(columns = 'Stock Name')\n",
    "    df = df.rename({0: 'Cluster'},axis = 'columns')\n",
    "    df = df.set_index('StockName')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=pd.read_parquet(\"us_equities_logreturns.parquet\")\n",
    "\n",
    "DF_cut=DF.iloc[-5000:]\n",
    "\n",
    "sel=DF_cut.isnull().sum(axis=0)>0\n",
    "DF_cut=DF_cut.drop(columns=DF_cut.columns[sel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_louvain = LouvainCorrelationClustering(DF_cut)\n",
    "df_agg = aggregateClusters_(DF_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('strategy mean: ',compute_stategy_avg_return(DF,65,10,clustering = 'louvian', inter_cluster_strategy ='inverse std', intra_cluster_strategy = 'equal weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('strategy inv std: ',compute_stategy_avg_return(DF,65,10,inter_cluster_strategy ='equal weight',clustering = 'louvian',intra_cluster_strategy = 'equal weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('strategy mean: ',compute_stategy_avg_return(DF,65,10,inter_cluster_strategy ='equal weight',clustering = 'louvian',intra_cluster_strategy = 'equal weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('strategy mean: ',compute_stategy_avg_return(DF,65,10,inter_cluster_strategy ='equal weight',clustering = 'louvian',intra_cluster_strategy = 'equal weight'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood clustering\n",
    "\n",
    "\n",
    "\n",
    "There is no code for this method in Python. The following shows how to call R from Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
